{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카메라로 관찰하고자 하는 대상을 30p만 녹화한다.\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0) # camera 녹화시\n",
    "\n",
    "# 카메라 width, height\n",
    "w = int(cap.get(3))\n",
    "h = int(cap.get(4))\n",
    "size = (w,h)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "\n",
    "# videowriter 객체 생성\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "file_name = './input/input_1.avi' # ROI 지정할 것\n",
    "out = cv2.VideoWriter(file_name , fourcc, fps, size)\n",
    "\n",
    "frame_counter = 1\n",
    "# 30p 만 읽기\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "            ret, img = cap.read()\n",
    "        \n",
    "        # 가우시안 필터 & 노이즈 제거\n",
    "        # blur1 = cv2.GaussianBlur(img, (3,3), 0)\n",
    "        \n",
    "        # bilateral filter & 노이즈 제거 & 선명함\n",
    "            blur2 = cv2.bilateralFilter(img, 5, 75, 75)\n",
    "        \n",
    "#         emerged = np.hstack((img, blur2))\n",
    "        \n",
    "            if ret:\n",
    "#             print(\"Current frame is {}\".format(frame_counter))\n",
    "                cv2.imshow('Bilateral', blur2)\n",
    "                out.write(blur2)\n",
    "            \n",
    "                frame_counter += 1\n",
    "        \n",
    "        # 30p 받아서 저장하기 위함\n",
    "            if frame_counter == 30 :\n",
    "                out.write(blur2)\n",
    "                break\n",
    "        \n",
    "        \n",
    "            if cv2.waitKey(50) & 0xFF == 27:\n",
    "                break\n",
    "            \n",
    "else:\n",
    "    print('no camera')\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 녹화한 거 읽어오기 & ROI 지정해서 사이즈 줄여서 다시 저장\n",
    "# \"file_name\" 가져오기\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 저장한 video 가져오기\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 첫 프레임 읽어서, ROI 지정\n",
    "win_name = 'ROI'\n",
    "if cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # ROI 지정\n",
    "    x, y, w, h = cv2.selectROI(win_name, img, False)\n",
    "    \n",
    "    \n",
    "    # videowriter_roi 객체 생성\n",
    "    size = (int(w), int(h))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    file_name = './input/input_1_roi.avi' \n",
    "    out = cv2.VideoWriter(file_name , fourcc, fps, size)\n",
    "\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 1) # 첫프레임에서 ROI 지정하고, 다시 시작\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        cv2.imshow('Test', roi)\n",
    "        out.write(roi)\n",
    "        \n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            cv2.imshow('Test', roi)\n",
    "            out.write(roi)\n",
    "            break\n",
    "        \n",
    "        if cv2.waitKey(66) & 0xFF == 27:\n",
    "            break\n",
    "else:\n",
    "    print('There\\'s no Video')\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import cv2\n",
    "from numpy.fft import fft2, fftshift, ifft2, ifftshift\n",
    "from numpy.fft import fft, ifft\n",
    "from numpy import tile, real, min, zeros\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import firwin\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "import math\n",
    "\n",
    "M_PI = math.pi\n",
    "eps = 2**(-52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Frequency =1.5\n",
      "High Frequency = 2.5\n",
      "alpha = 30\n",
      "Sampling Rate = 30\n",
      "reference Frame = 0\n",
      "Number of Pyramid = 2\n",
      "Orientation = 2\n",
      "sigma = 5\n",
      "AttenuateOtherFreq = 0\n",
      "rationOfFrame = 0\n",
      "30\n",
      "137\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "# ROI 된 Video PBM 실행하기\n",
    "fileName = file_name\n",
    "\n",
    "# PBM parameter setting - alpha, Low_Freq, High_Freq\n",
    "Low_Freq = float(input('Low Frequency ='))\n",
    "High_Freq = float(input('High Frequency = '))\n",
    "alpha = float(input('alpha = '))\n",
    "\n",
    "# Sampling_Rate = 2200\n",
    "# refFrame = 0\n",
    "# NumberOfPyramid = 2\n",
    "# Orientation = 2\n",
    "# sigma = 5\n",
    "# attenuateOtherFreq = 0\n",
    "# ratioOfFrame = 1\n",
    "\n",
    "\n",
    "Sampling_Rate = int(input('Sampling Rate = '))\n",
    "refFrame = int(input('reference Frame = '))\n",
    "NumberOfPyramid = int(input('Number of Pyramid = '))\n",
    "Orientation = int(input('Orientation = '))\n",
    "sigma = int(input('sigma = '))\n",
    "attenuateOtherFreq = int(input('AttenuateOtherFreq = '))\n",
    "ratioOfFrame = int(input('rationOfFrame = '))\n",
    "\n",
    "# Video Information Checking\n",
    "cap_original = cv2.VideoCapture(fileName)\n",
    "\n",
    "ret, frame = cap_original.read()\n",
    "\n",
    "\n",
    "\n",
    "frameX = frame.shape[1]\n",
    "frameY = frame.shape[0]\n",
    "nColor = frame.shape[2]\n",
    "nFrame = int(cap_original.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(nFrame)\n",
    "print(frameX)\n",
    "print(frameY)\n",
    "\n",
    "# ready_1\n",
    "pyrLayers =NumberOfPyramid\n",
    "rVals =[1]\n",
    "for i in range(pyrLayers):\n",
    "    rVals.append(0.5**(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-vijyisc5\\opencv\\modules\\imgproc\\src\\pyramids.cpp:749: error: (-215:Assertion failed) !_src.empty() in function 'cv::pyrDown_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7d7146c79de2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0mvidFFT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfftshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfft2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtVid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap_original\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyrDown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfir_window_bp_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-vijyisc5\\opencv\\modules\\imgproc\\src\\pyramids.cpp:749: error: (-215:Assertion failed) !_src.empty() in function 'cv::pyrDown_'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# ready_2 - Definition\n",
    "def getFilters(dimension, rVals, orientations):\n",
    "    X = int(dimension[1])\n",
    "    Y = int(dimension[0])\n",
    "\n",
    "    defaultTwidth = 1\n",
    "    twidth = defaultTwidth\n",
    "\n",
    "    polarGrid = getPolarGrid(dimension)\n",
    "    count = 0\n",
    "\n",
    "    angle = np.array(polarGrid[0]) #픽셀 위치별 각도 값\n",
    "    rad = np.array(polarGrid[1]) #픽셀 위치별 거리 값\n",
    "\n",
    "    mask = getRadialMaskPair(rVals[0], rad, twidth)\n",
    "    himask = mask[0]\n",
    "    lomaskPrev = mask[1]\n",
    "\n",
    "    filters = []\n",
    "    filters.append(himask)\n",
    "\n",
    "    for k in range(1, len(rVals)):\n",
    "        mask = getRadialMaskPair(rVals[k], rad, twidth)\n",
    "        himask = mask[0]\n",
    "        lomask = mask[1]\n",
    "\n",
    "        radMask = himask*lomaskPrev\n",
    "\n",
    "        for j in range(1, orientations+1):\n",
    "            angleMask = getAngleMask(j, orientations, angle)\n",
    "            filters.append(radMask*angleMask/2)\n",
    "\n",
    "        lomaskPrev = lomask\n",
    "    filters.append(lomask)\n",
    "\n",
    "    for k in range(len(filters)):\n",
    "        filters[k] = np.array(filters[k])\n",
    "    return filters\n",
    "\n",
    "#화면의 너비x높이 크기의 극좌표르를 2차원 배열으로 형성한다.\n",
    "def getPolarGrid(dimension):\n",
    "    X = dimension[1]\n",
    "    Y = dimension[0]\n",
    "    centerX = int(X / 2)\n",
    "    centerY = int(Y / 2)\n",
    "\n",
    "    # Create rectangular grid\n",
    "    xramp = np.array([ [(x-int(X/2))/(X/2) for x in range(X)] for y in range(Y)])\n",
    "    yramp = np.array([ [(y-int(Y/2))/(Y/2) for x in range(X)] for y in range(Y)])\n",
    "    angle = np.arctan2(xramp, yramp)+M_PI/2\n",
    "\n",
    "    rad = np.sqrt(xramp**2+yramp**2)\n",
    "    rad[centerY][centerX] = rad[centerY-1][centerX]\n",
    "\n",
    "    polarGrid = [angle, rad]\n",
    "    return polarGrid\n",
    "\n",
    "#3차원 그래프상으로 보이는 완전 꼬깔 형태에서, 위 아래의 범위를 잘라내고 원뿔대 같은 형태도 만든다.\n",
    "def getRadialMaskPair(r, rad, twidth): \n",
    "    X = int(rad.shape[1])\n",
    "    Y = int(rad.shape[0])\n",
    "\n",
    "    log_rad = np.log2(rad)-np.log2(r)\n",
    "\n",
    "    himask = log_rad\n",
    "    himask[himask>0] = 0\n",
    "    himask[himask<-twidth] = -twidth\n",
    "    himask = himask*M_PI/(2*twidth)\n",
    "\n",
    "    himask = np.cos(himask)\n",
    "    lomask = np.sqrt(1-himask**2)\n",
    "\n",
    "    mask = [himask, lomask]\n",
    "    return mask\n",
    "\n",
    "def getAngleMask(b, orientations, angle):\n",
    "    order = orientations - 1\n",
    "    const = (2 ** (2 * order)) * (math.factorial(order) ** 2) / (orientations * math.factorial(2 * order)) # Scaling constant\n",
    "\n",
    "    angle_ = (M_PI + angle - (M_PI * (b - 1) / orientations)) % (2 * M_PI) - M_PI\n",
    "    anglemask = 2 * np.sqrt(const) * (np.cos(angle_) ** order) * (abs(angle_) < (M_PI / 2))  # Make falloff smooth\n",
    "    return anglemask\n",
    "\n",
    "filters = getFilters([frameY, frameX], rVals, Orientation)\n",
    "\n",
    "def getFilterIDX2(filters, orientations, rVals):\n",
    "    X = filters[0].shape[1]\n",
    "    Y = filters[0].shape[0]\n",
    "    nFilts = len(filters)\n",
    "    filtIDX = [[None for j in range(orientations)] for i in range(nFilts)]\n",
    "    croppedFilters = []\n",
    "\n",
    "    #himask IDX\n",
    "    filtIDX[0][0] = [y for y in range(Y)]\n",
    "    filtIDX[0][1] = [x for x in range(X)]\n",
    "    croppedFilters.append(filters[0])\n",
    "\n",
    "    #stearable filter IDX\n",
    "    for k in range(1, nFilts-1, orientations):\n",
    "        n = int(k/2)+1\n",
    "        lb_y = int( (Y*(np.sum(rVals[0:n])-1))/2 )\n",
    "        ub_y = Y - lb_y\n",
    "        lb_x = int( (X*(np.sum(rVals[0:n])-1))/2 )\n",
    "        ub_x = X - lb_x\n",
    "\n",
    "        for i in range(orientations):\n",
    "            filtIDX[k+i][0] = [y + lb_y for y in range(ub_y - lb_y)]\n",
    "            filtIDX[k+i][1] = [x + lb_x for x in range(ub_x - lb_x)]\n",
    "\n",
    "        for i in range(orientations):\n",
    "            croppedFilters.append(filters[k+i][lb_y:ub_y, lb_x:ub_x])\n",
    "\n",
    "\n",
    "    #lomaskIDX\n",
    "    lb_y = int( (Y * (np.sum(rVals) - 1))/2 )\n",
    "    ub_y = Y - lb_y\n",
    "    lb_x = int( (X * (np.sum(rVals) - 1))/2 )\n",
    "    ub_x = X - lb_x\n",
    "\n",
    "\n",
    "    filtIDX[nFilts - 1][0] = [y + lb_y for y in range(ub_y - lb_y)]\n",
    "    filtIDX[nFilts - 1][1] = [x + lb_x for x in range(ub_x - lb_x)]\n",
    "    croppedFilters.append(filters[nFilts-1][lb_y:ub_y, lb_x:ub_x])\n",
    "\n",
    "    filterIDX = [croppedFilters, filtIDX]\n",
    "    return filterIDX\n",
    "\n",
    "\n",
    "filterIDX = getFilterIDX2(filters, Orientation, rVals)\n",
    "croppedFilters = filterIDX[0]\n",
    "filtIDX = filterIDX[1]\n",
    "\n",
    "def bgr2yiq(img):\n",
    "    R = img[:, :, 2]\n",
    "    G = img[:, :, 1]\n",
    "    B = img[:, :, 0]\n",
    "\n",
    "    Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    I = 0.596 * R - 0.274 * G - 0.322 * B\n",
    "    Q = 0.211 * R - 0.523 * G + 0.312 * B\n",
    "\n",
    "    img_yiq = np.zeros([img.shape[0], img.shape[1], img.shape[2]])\n",
    "    img_yiq[:, :, 0] = Y\n",
    "    img_yiq[:, :, 1] = I\n",
    "    img_yiq[:, :, 2] = Q\n",
    "    #YIQ = np.array([[0.299, 0.587, 0.114],[0.596, -0.274, -0.322],[0.211, -0.523, 0.312]])\n",
    "    return img_yiq\n",
    "\n",
    "def yiq2bgr(img):\n",
    "    Y = img[:, :, 0]\n",
    "    I = img[:, :, 1]\n",
    "    Q = img[:, :, 2]\n",
    "\n",
    "    R = Y+0.956*I+0.621*Q\n",
    "    G = Y-0.272*I-0.647*Q\n",
    "    B = Y-1.106*I+1.703*Q\n",
    "\n",
    "    img_rgb = np.zeros([img.shape[0], img.shape[1], img.shape[2]])\n",
    "    img_rgb[:, :, 0] = B\n",
    "    img_rgb[:, :, 1] = G\n",
    "    img_rgb[:, :, 2] = R\n",
    "    #YIQ = np.array([[0.299, 0.587, 0.114],[0.596, -0.274, -0.322],[0.211, -0.523, 0.312]])\n",
    "    return img_rgb\n",
    "\n",
    "vidFFT = np.zeros([nFrame,frameY,frameX], dtype=np.complex64)\n",
    "\n",
    "for k in range(0, nFrame):\n",
    "    clipMat = frame/255\n",
    "    tVid = bgr2yiq(clipMat)[:,:,0]\n",
    "    vidFFT[k] = fftshift(fft2(tVid))\n",
    "    ret, frame = cap_original.read()\n",
    "    \n",
    "    \n",
    "def fir_window_bp_2(delta, fl, fh):\n",
    "    length = delta.shape[0]+1\n",
    "    b = firwin(length, (fl * 2, fh * 2), pass_zero=False)[0:length-1]\n",
    "\n",
    "    m = delta.shape[1]\n",
    "    batches = 20\n",
    "    batch_size = int(m / batches) + 1\n",
    "    temp = fft(ifftshift(b))\n",
    "    out = zeros(delta.shape, dtype=delta.dtype)\n",
    "\n",
    "    i=0\n",
    "    indexes = (batch_size * i, min((batch_size * (i + 1), m)))\n",
    "    while (indexes[0]<m):\n",
    "        indexes = (batch_size * i, min((batch_size * (i + 1), m)))\n",
    "        freq = fft(delta[:, indexes[0]:indexes[1]], axis=0) * tile(temp, (\n",
    "            delta.shape[2], indexes[1] - indexes[0], 1)).swapaxes(0, 2)\n",
    "        out[:, indexes[0]:indexes[1]] = real(ifft(freq, axis=0))\n",
    "        i += 1\n",
    "        indexes = (batch_size * i, min((batch_size * (i + 1), m)))\n",
    "    return out\n",
    "\n",
    "def amplitude_weighted_blur(x, weight, sigma):\n",
    "    if sigma != 0:\n",
    "        return gaussian(x*weight, sigma, mode=\"wrap\") / gaussian(weight, sigma, mode=\"wrap\")\n",
    "    return x\n",
    "\n",
    "magnifiedLumaFFT = np.zeros([nFrame, frameY, frameX], dtype=np.complex64)\n",
    "numLevels = len(filters)\n",
    "\n",
    "for level in range(1, numLevels-1):\n",
    "    X = len(croppedFilters[level][0])\n",
    "    Y = len(croppedFilters[level])\n",
    "    lb_x = filtIDX[level][1][0]\n",
    "    ub_x = filtIDX[level][1][-1]+1\n",
    "    lb_y = filtIDX[level][0][0]\n",
    "    ub_y = filtIDX[level][0][-1]+1\n",
    "\n",
    "    # 1. 기준프레임 설정\n",
    "    clipMat = croppedFilters[level] * vidFFT[refFrame][lb_y:ub_y, lb_x:ub_x]\n",
    "    pyrRef = ifft2(ifftshift(clipMat))\n",
    "    pyrRefPhaseOrig = pyrRef / abs(pyrRef)\n",
    "    pyrRef = np.angle(pyrRef)\n",
    "\n",
    "    delta = np.zeros([nFrame,Y,X], dtype=np.float16)\n",
    "    matCheck = []\n",
    "    \n",
    "    # 2. 각 프레임간 차이 계산\n",
    "    for frameIDX in range(0, nFrame):\n",
    "        filterResponse = ifft2(ifftshift( croppedFilters[level] * vidFFT[frameIDX][lb_y:ub_y, lb_x:ub_x] ))\n",
    "        pyrCurrent = np.angle(filterResponse)\n",
    "        clipMat1 = pyrCurrent - pyrRef\n",
    "        clipMat2 = M_PI + clipMat1\n",
    "        clipMat3 = clipMat2%(2*M_PI)\n",
    "        clipMat4 = clipMat3 - M_PI\n",
    "        clipMat = clipMat4\n",
    "        delta[frameIDX] = clipMat\n",
    "\n",
    "    # 3. 픽셀 변화 양상에 대한 band pass filtering\n",
    "    delta_1 = fir_window_bp_2(delta, Low_Freq / Sampling_Rate, High_Freq / Sampling_Rate)  # Finite Impulse Response filter\n",
    "\n",
    "    for frameIDX in range(0, nFrame):\n",
    "        Phase = delta_1[frameIDX]\n",
    "\n",
    "        originalLevel = ifft2(ifftshift(croppedFilters[level]*vidFFT[frameIDX][lb_y:ub_y, lb_x:ub_x]))\n",
    "\n",
    "        if (sigma != 0):\n",
    "            Phase = amplitude_weighted_blur(Phase, abs(originalLevel)+eps, sigma)\n",
    "        \n",
    "        # 4. alpha 계수 곱 및 병합\n",
    "        Phase = alpha*Phase\n",
    "\n",
    "        if (attenuateOtherFreq):\n",
    "            tempOrig = abs(originalLevel)*pyrRefPhaseOrig\n",
    "        else:\n",
    "            tempOrig = originalLevel\n",
    "\n",
    "        tempTransformOut = np.exp(1j*Phase)*tempOrig\n",
    "\n",
    "\n",
    "        A = croppedFilters[level]\n",
    "        B = fftshift(fft2(tempTransformOut))\n",
    "        curLevelFrame = 2 * A * B\n",
    "\n",
    "        matClip = magnifiedLumaFFT[frameIDX][lb_y:ub_y, lb_x:ub_x]\n",
    "        magnifiedLumaFFT[frameIDX][lb_y:ub_y, lb_x:ub_x] = matClip + curLevelFrame\n",
    "\n",
    "#5. lowpass residual 처리\n",
    "level = len(filters)-1\n",
    "lb_x = filtIDX[level][1][0]\n",
    "ub_x = filtIDX[level][1][-1] + 1\n",
    "lb_y = filtIDX[level][0][0]\n",
    "ub_y = filtIDX[level][0][-1] + 1\n",
    "for frameIDX in range(0, nFrame):\n",
    "    lowpassFrame = vidFFT[frameIDX][lb_y:ub_y, lb_x:ub_x]*(croppedFilters[level]**2)\n",
    "    matClip = magnifiedLumaFFT[frameIDX][lb_y:ub_y, lb_x:ub_x] + lowpassFrame\n",
    "    magnifiedLumaFFT[frameIDX][lb_y:ub_y, lb_x:ub_x] = matClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (346,290) into shape (114,137)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-708373e4f3c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mclipMat2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbgr2yiq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mclipMat3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagnifiedLuma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mclipMat2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclipMat3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#그 외의 Q, I는 그대로 사용할 것이므로 변환된 Y만 원본 영상에 대입한 뒤 다시 RGB로 변환한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (346,290) into shape (114,137)"
     ]
    }
   ],
   "source": [
    "cap_original = cv2.VideoCapture(fileName)\n",
    "\n",
    "fps = cap_original.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "FileName = './output/roi_1.avi'\n",
    "obj_out = cv2.VideoWriter(FileName, fourcc, fps, (frameX, frameY))\n",
    "\n",
    "ret, frame = cap_original.read()\n",
    "# frame = cv2.pyrDown(frame)\n",
    "\n",
    "for k in range(0, nFrame):\n",
    "    clipMat1 = magnifiedLumaFFT[k]\n",
    "    clipMat = ifft2(ifftshift(clipMat1))\n",
    "    magnifiedLuma = np.real(clipMat)\n",
    "    #명암에 대한 데이터만 적용하기 위해 yiq변환해서 Y 값만 가져온다.\n",
    "    clipMat2 = bgr2yiq(frame)\n",
    "    clipMat3 = magnifiedLuma*255\n",
    "    clipMat2[:,:,0] = clipMat3\n",
    "    \n",
    "    #그 외의 Q, I는 그대로 사용할 것이므로 변환된 Y만 원본 영상에 대입한 뒤 다시 RGB로 변환한다.\n",
    "    outFrame = yiq2bgr(clipMat2)\n",
    "    \n",
    "    outFrame[outFrame > 255] = 255\n",
    "    outFrame[outFrame < 0] = 0\n",
    "    outFrame = np.uint8(outFrame)\n",
    "    obj_out.write(outFrame)\n",
    "    ret, frame = cap_original.read()\n",
    "\n",
    "cap_original.release()\n",
    "obj_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e8896655e5e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# original - PBM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0msum1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     # 평균블러링\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "# 동시 display\n",
    "cap1 = cv2.VideoCapture(fileName)\n",
    "cap2 = cv2.VideoCapture(FileName)\n",
    "\n",
    "w = int(cap1.get(3))\n",
    "h = int(cap1.get(4))\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap1.read()\n",
    "    ret, frame2 = cap2.read()\n",
    "    \n",
    "    # original - PBM\n",
    "    sum1 = np.hstack((frame1, frame2))\n",
    "    \n",
    "#     # 평균블러링\n",
    "#     blur_av1 = cv2.blur(frame1, (10,10))\n",
    "#     blur_av2 = cv2.blur(frame2, (10,10))\n",
    "#     sum2 = np.hstack((blur_av1, blur_av2))\n",
    "    \n",
    "    # 가우시안블러링\n",
    "    blur_gau1 = cv2.GaussianBlur(frame1, (3, 3), 0)\n",
    "    blur_gau2 = cv2.GaussianBlur(frame2, (3, 3), 0)\n",
    "    sum3 = np.hstack((blur_gau1, blur_gau2))\n",
    "    \n",
    "#     # 미디언블러링\n",
    "#     blur_median1 = cv2.medianBlur(frame1, 5)\n",
    "#     blur_median2 = cv2.medianBlur(frame2, 5)\n",
    "#     sum4 = np.hstack((blur_median1, blur_median2))\n",
    "    \n",
    "    # 바이레터럴 블러링\n",
    "    blur_bi1 = cv2.bilateralFilter(frame1, 5, 75, 75)\n",
    "    blur_bi2 = cv2.bilateralFilter(frame2, 5, 75, 75)\n",
    "    sum5 = np.hstack((blur_bi1, blur_bi2))\n",
    "    \n",
    "    sum = np.vstack((sum1, sum3, sum5))\n",
    "#     sum = cv2.pyrUp(sum)\n",
    "#     sum = cv2.pyrDown(sum)\n",
    "    cv2.putText(sum, 'Original', (0,h-5), 1, 1, (255,255,255), 2)\n",
    "    cv2.putText(sum, 'PBM', (w,h-5), 1, 1, (255,255,255), 2)\n",
    "    \n",
    "#     cv2.putText(sum, 'Original with Blur', (0,2*h-5), 1, 1, 5)\n",
    "#     cv2.putText(sum, 'PBM with Blur', (w,2*h-5), 1, 1, 5)\n",
    "    \n",
    "    cv2.putText(sum, 'Original with Gaussian Blur', (0,2*h-5), 1, 1, (255,255,255), 2)\n",
    "    cv2.putText(sum, 'PBM with Gaussian Blur', (w,2*h-5), 1, 1, (255,255,255), 2)\n",
    "    \n",
    "#     cv2.putText(sum, 'Original with Median Blur', (0,4*h-5), 1, 1, 5)\n",
    "#     cv2.putText(sum, 'PBM with Median Blur', (w,4*h-5), 1, 1, 5)\n",
    "    \n",
    "    cv2.putText(sum, 'Original with Bilateral Blur', (0,3*h-5), 1, 1, (255,255,255), 2)\n",
    "    cv2.putText(sum, 'PBM with Bilateral Blur', (w,3*h-5), 1, 1, (255,255,255), 2)\n",
    "    \n",
    "    cv2.imshow('Sum', sum)\n",
    "    \n",
    "    if cap1.get(cv2.CAP_PROP_POS_FRAMES) == cap1.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        cv2.imshow('Sum', sum)\n",
    "        cap1.set(cv2.CAP_PROP_POS_FRAMES, 1)\n",
    "        cap2.set(cv2.CAP_PROP_POS_FRAMES, 1)\n",
    "    \n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
